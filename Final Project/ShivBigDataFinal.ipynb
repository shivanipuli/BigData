{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUSN 20800 Big Data Final project\n",
    "\n",
    "## Due date: March 8th, 2024, 11:59 a.m. (not p.m.!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Text Analysis of Presidents' Addresses (50 points)\n",
    "\n",
    "The State of the Union is an annual address by the President of the United States before a joint session of congress. In it, the President reviews the previous year and lays out his legislative agenda for the coming year. This dataset contains the full text of the State of the Union address from 1790 (Washington) to 2021 (Biden). http://stateoftheunion.onetwothree.net/texts/index.html\n",
    "\n",
    "In this project, you are requested to analyze the addresses delivered by presidents. All functions are provided as given and you don't need to modify any of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following codes to load the data, you don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              president                                               text  \\\n",
       "0          James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1      William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2  Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3       Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4         James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "\n",
       "   year  \n",
       "0  1821  \n",
       "1  1897  \n",
       "2  1960  \n",
       "3  1923  \n",
       "4  1816  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1: Load Data\n",
    "open_file = open('speech', \"rb\")\n",
    "speeches = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "df_speech = pd.DataFrame(speeches)\n",
    "df_speech.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part I. LDA model (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is LDA?\n",
    "\n",
    "latent Dirichlet allocation (LDA) is a generative probabilistic model for collections ofdiscrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. The \"latent\" part of LDA refers to the fact that the topic structure—the topics themselves, the distribution of topics in each document, and the distribution of words in each topic—are hidden structures that the model aims to learn from the observed documents.\n",
    "\n",
    "Here are some key concepts:\n",
    "\n",
    "- Document: In LDA, a document is a sequence of words. A document can be as long or as short as desired, but LDA typically works best with documents that are not too short, as longer documents provide more context for learning relationships between words.\n",
    "\n",
    "- Corpus: A collection of documents. The corpus is the entire dataset that you wish to analyze using LDA.\n",
    "\n",
    "- Topic: An abstract theme or subject area that is prevalent across a collection of documents. In LDA, a topic is represented as a distribution over words, meaning that each topic is characterized by certain words that are more likely to appear in that topic.\n",
    "\n",
    "- Word: The basic unit of text analysis in LDA. Words are considered tokens and are the elements that are distributed across topics.\n",
    "\n",
    "Link of the original paper: https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following codes to preprocess the data, you don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyLDAvis # run this code if you don't have this package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/shivanipuli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/shivanipuli/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shivanipuli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/shivanipuli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shivanipuli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    Convert treebank tag to wordnet tag.\n",
    "    \n",
    "    Parameters:\n",
    "    - treebank_tag (str): The part-of-speech tag in Penn Treebank notation.\n",
    "    \"\"\"\n",
    "    \n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ  # Adjective\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB  # Verb\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN  # Noun\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV   # Adverb\n",
    "    else:\n",
    "        return wordnet.VERB  # Default to verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeText(input):\n",
    "    \"\"\"\n",
    "    Cleans and normalizes the input text by removing various types of characters and patterns.\n",
    "\n",
    "    Parameters:\n",
    "    - input (str): The text to be normalized.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\n+', \" \", input)  # change \\n to \" \"\n",
    "    text = re.sub(r'\\[[0-9]*\\]', \"\", text)  # Delete [1]\n",
    "    text = re.sub(r' +', \" \", text)  # Change several \" \" to one \" \"\n",
    "    text = re.sub(r'\\(end\\)', \"\", text)  # Delete (end)\n",
    "\n",
    "    text = re.sub(r'@[^\\s]+', '', text)\n",
    "    text = re.sub(r'#([^\\s]+)', '', text)\n",
    "    text = re.sub(r'[:;>?<=*+()&,\\-#!$%\\{˜|\\}\\[^_\\\\@\\]1234567890’‘]', ' ', text)  # Special char\n",
    "    text = re.sub(r'[\\d]', '', text)  # decimal digit\n",
    "    text = text.replace(\".\", '')  # Delete .\n",
    "    text = text.replace(\"`\", '')  # Delete `\n",
    "    text = text.replace(\"'s\", '')  # Delete 's\n",
    "    text = text.replace(\"'\", '')  # Delete '\n",
    "    text = text.replace(\"/\", ' ')\n",
    "    text = text.replace(\"\\\"\", ' ')\n",
    "    text = text.replace(\"\\\\\", '')\n",
    "    text = re.sub(r\"\\b[a-z]\\b\", \"\", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Delete \\s\n",
    "\n",
    "    text = text.strip()  # delete spaces at beginning and ending\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(text):\n",
    "    \"\"\"\n",
    "    The function leverages NLTK for tokenization, stopword removal, \n",
    "    part-of-speech tagging, and lemmatization.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The text to be cleaned and processed.\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = normalizeText(text)\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    word = [w for w in tokenized_text if w.isalpha()]\n",
    "    \n",
    "    # delete stop words\n",
    "    stop_words = set(stopwords.words('english'))  # Stopwords_set\n",
    "    stop_words.add('could')\n",
    "    stop_words.add('would')\n",
    "    stop_words.add('shall')\n",
    "    tokens = [w for w in word if not w in stop_words]\n",
    "        \n",
    "    # lemmatize\n",
    "    res    = []\n",
    "    for w, pos in nltk.tag.pos_tag(tokens):\n",
    "        wordnet_pos = get_wordnet_pos(pos)\n",
    "        res.append(WordNetLemmatizer().lemmatize(w, pos=wordnet_pos))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              president                                               text  \\\n",
       "0          James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1      William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2  Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3       Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4         James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "\n",
       "   year  \n",
       "0  1821  \n",
       "1  1897  \n",
       "2  1960  \n",
       "3  1923  \n",
       "4  1816  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches = pd.DataFrame(speeches)\n",
    "df_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 s, sys: 172 ms, total: 46.2 s\n",
      "Wall time: 46.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "      <td>[senate, house, representative, give, pleasure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "      <td>[deliver, person, joint, session, mr, presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "      <td>[since, close, last, congress, nation, lose, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              president                                               text  \\\n",
       "0          James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1      William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2  Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3       Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4         James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "\n",
       "   year                                               word  \n",
       "0  1821  [fellow, citizen, senate, house, representativ...  \n",
       "1  1897  [senate, house, representative, give, pleasure...  \n",
       "2  1960  [deliver, person, joint, session, mr, presiden...  \n",
       "3  1923  [since, close, last, congress, nation, lose, p...  \n",
       "4  1816  [fellow, citizen, senate, house, representativ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cleaned_word = df_speeches['text'].map(clean_word)\n",
    "df_speeches['word'] = cleaned_word\n",
    "\n",
    "df_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Perform LDA on these speeches and visualize the topic models. What's your conclusion?\n",
    "\n",
    "(You can try different parameters to see the difference.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To avoid warnings during visualization, you need to run the below codes.\n",
    "#!pip install --upgrade bottleneck\n",
    "#!pip install pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el16147511402887874090245033217064\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el16147511402887874090245033217064_data = {\"mdsDat\": {\"x\": [0.12206470839817124, 0.09059747280679227, -0.19873445261934183, -0.0139277285856216], \"y\": [0.052000010389088136, -0.02550113421103023, 0.02384164845672924, -0.050340524634787144], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [29.060630561892935, 27.875581895742897, 22.529913147498938, 20.533874394865233]}, \"tinfo\": {\"Term\": [\"program\", \"help\", \"job\", \"economic\", \"billion\", \"today\", \"budget\", \"get\", \"percent\", \"problem\", \"goal\", \"object\", \"challenge\", \"mexico\", \"cut\", \"worker\", \"school\", \"nuclear\", \"territory\", \"corporation\", \"industrial\", \"cent\", \"method\", \"back\", \"fight\", \"per\", \"woman\", \"weapon\", \"move\", \"gold\", \"providence\", \"entertain\", \"commence\", \"object\", \"stipulation\", \"communicate\", \"paper\", \"mode\", \"amicable\", \"militia\", \"mexico\", \"inform\", \"cherish\", \"blessing\", \"portion\", \"tribe\", \"derive\", \"french\", \"acknowledge\", \"feeling\", \"france\", \"execution\", \"embarrassment\", \"expose\", \"happy\", \"british\", \"deliberation\", \"patriotism\", \"inconvenience\", \"minister\", \"article\", \"satisfaction\", \"consequence\", \"intercourse\", \"deem\", \"extent\", \"mexican\", \"navigation\", \"territory\", \"render\", \"britain\", \"bank\", \"port\", \"vessel\", \"occasion\", \"late\", \"spain\", \"convention\", \"constitutional\", \"coast\", \"indian\", \"friendly\", \"exercise\", \"commercial\", \"appear\", \"property\", \"navy\", \"gold\", \"bond\", \"pension\", \"reservation\", \"postal\", \"commend\", \"cuba\", \"award\", \"november\", \"interior\", \"cent\", \"per\", \"statute\", \"diplomatic\", \"june\", \"appointment\", \"postmaster\", \"february\", \"precede\", \"prior\", \"native\", \"attorney\", \"concur\", \"suggestion\", \"approval\", \"quite\", \"advise\", \"island\", \"commissioner\", \"july\", \"bureau\", \"note\", \"indian\", \"mail\", \"spanish\", \"total\", \"court\", \"district\", \"product\", \"fiscal\", \"suggest\", \"vessel\", \"convention\", \"commercial\", \"territory\", \"navy\", \"currency\", \"march\", \"international\", \"post\", \"appoint\", \"naval\", \"tariff\", \"annual\", \"spain\", \"class\", \"property\", \"nuclear\", \"job\", \"goal\", \"spending\", \"speaker\", \"percent\", \"today\", \"commitment\", \"challenge\", \"billion\", \"democracy\", \"weapon\", \"basic\", \"decade\", \"help\", \"leadership\", \"threat\", \"inflation\", \"middle\", \"ahead\", \"start\", \"poverty\", \"program\", \"americans\", \"historic\", \"get\", \"tell\", \"budget\", \"hard\", \"ally\", \"cut\", \"move\", \"back\", \"fight\", \"worker\", \"woman\", \"economic\", \"achieve\", \"school\", \"expand\", \"reform\", \"income\", \"problem\", \"area\", \"deficit\", \"major\", \"century\", \"low\", \"industrial\", \"corporation\", \"farmer\", \"activity\", \"armament\", \"study\", \"merely\", \"definite\", \"reorganization\", \"attitude\", \"association\", \"committee\", \"agriculture\", \"employee\", \"farm\", \"veteran\", \"undertake\", \"deal\", \"safeguard\", \"lack\", \"disaster\", \"assist\", \"highway\", \"conference\", \"wage\", \"method\", \"combination\", \"outside\", \"undertaken\", \"railway\", \"agricultural\", \"enact\", \"employment\", \"problem\", \"railroad\", \"efficiency\", \"function\", \"international\", \"agency\", \"economic\", \"water\", \"court\", \"construction\", \"modern\", \"navy\", \"tariff\", \"ought\", \"fiscal\", \"bank\", \"relief\", \"per\", \"cent\"], \"Freq\": [1297.0, 1153.0, 846.0, 967.0, 560.0, 530.0, 653.0, 626.0, 404.0, 782.0, 340.0, 741.0, 354.0, 874.0, 467.0, 438.0, 679.0, 273.0, 1095.0, 402.0, 374.0, 617.0, 531.0, 437.0, 412.0, 675.0, 381.0, 270.0, 348.0, 445.0, 72.87128932735666, 136.98238941603702, 127.81458653595168, 617.6054442779749, 112.88250265820358, 161.45670666142436, 176.81071274964475, 126.17794936144735, 78.17847001596674, 128.29595293989402, 685.2380603504515, 122.71881839481081, 75.13580955740701, 102.72442469456671, 378.9632771342327, 200.86353772954365, 135.80170029802858, 171.7839335806159, 86.18331470917852, 88.33789800685297, 269.68715300074194, 199.6251413958, 104.3738742295904, 85.9810427920664, 145.80701880889598, 362.4091226180339, 80.76224159434092, 70.42947698375713, 65.50677029752416, 406.77855066798975, 361.77442063504367, 185.6669602966176, 240.79615711733888, 273.77837188486683, 258.2872821379889, 300.78710302447985, 193.6946006728742, 186.73126330749204, 617.2799243317862, 289.8825631787453, 313.9851757877765, 469.10172454124114, 272.11405485230085, 399.46694066787245, 237.84673452798148, 222.31529874381707, 269.9708994922977, 311.62274848599895, 222.79977794944264, 243.10241640642346, 326.8851075014573, 236.8290719489574, 260.3660145416087, 277.5874608705753, 226.57455732543818, 251.7203884433348, 270.25853268650764, 377.154310782845, 325.6295415782931, 254.08559442486109, 133.09503278245668, 198.2503230125663, 151.48217083946034, 242.70800852227623, 129.69380935388432, 132.5150901102422, 190.88867783075744, 436.6974013067331, 471.736691126567, 204.3090252102185, 164.54475864410904, 430.85988416829076, 174.06249625124065, 181.75760166476695, 119.12281152390806, 144.12707476777283, 69.84373547924767, 85.8210897003484, 88.96448109708007, 67.20377599215477, 181.73232902822835, 123.73011874248799, 78.30436917925688, 69.18494366571767, 395.48753003271656, 307.1898869165762, 225.11503667409949, 175.5243335142091, 270.44835635317537, 492.59433663246216, 229.48611402633952, 145.7281754756883, 322.3395128015408, 470.98092051926983, 318.23188453906664, 271.8578997141678, 448.92665196557, 207.83148965853007, 354.40484676634526, 308.3596206709357, 318.7982753373148, 417.3906576621562, 360.8890596603921, 225.08507903183178, 214.98529544885733, 296.0249243901963, 235.3354096651008, 218.98988657828963, 234.5459367102525, 232.83554669615674, 237.79563154683711, 224.30421724948556, 226.88954857998735, 226.76966852141948, 272.6979509100531, 842.2082877987452, 337.74459389447503, 212.95996888276903, 123.36120896006071, 395.69704935440427, 516.0750164506449, 219.31470910797776, 340.93571031370686, 537.2709946252487, 234.51841756365366, 254.63258407274552, 206.66116052594285, 199.6069586208255, 1046.0607085570277, 162.28345618685339, 207.80977044189498, 217.22707045345254, 189.8901064550485, 180.2087333600143, 238.19597457551214, 110.75514580096844, 1149.8946823019342, 147.51868290138532, 120.41017958587399, 551.1937766305675, 199.5154943497637, 569.1469597394912, 254.15891647890567, 237.69460104067136, 394.1026644473909, 295.77529314186484, 350.8741166766025, 332.3564683519832, 349.990913142539, 306.18846040329817, 631.1930679796895, 286.7960083246108, 462.0125924375071, 260.53045626410534, 369.8277269159709, 308.2738724494754, 374.41318014848275, 288.03357591061024, 254.4984809184686, 257.07686671949114, 262.53680371445216, 255.64090432978918, 299.7896197662325, 319.82337995013654, 250.60748657633908, 189.03471443526715, 75.4823066495531, 152.13856934499552, 146.66084095295915, 64.55945908054686, 83.2718442908257, 66.3213045304615, 84.7490532774983, 141.14344925629186, 263.10429534754223, 146.3154518268794, 230.50567660507812, 133.95786562955993, 95.31183848502596, 231.49213118330354, 73.47447944596469, 90.88238668785404, 71.12297043685433, 97.29658951965172, 60.85076997308858, 215.46378148322958, 236.7916784981944, 291.3307638593133, 106.71813118621237, 59.73639394637982, 56.521187314736856, 101.76223529747412, 191.547477136918, 151.54225877978476, 199.74394035483743, 370.1347993612185, 186.14248910686712, 191.3402047756774, 124.27329938311694, 327.0932116439659, 171.71362535512276, 333.22546962464645, 197.17078346690727, 297.0327041489431, 228.65749298745433, 124.48246741700537, 261.53115438831793, 187.03767190780005, 185.23069486677045, 248.8843687464792, 240.7301571554598, 158.32766104986686, 159.34687674000557, 157.3353128739864], \"Total\": [1297.0, 1153.0, 846.0, 967.0, 560.0, 530.0, 653.0, 626.0, 404.0, 782.0, 340.0, 741.0, 354.0, 874.0, 467.0, 438.0, 679.0, 273.0, 1095.0, 402.0, 374.0, 617.0, 531.0, 437.0, 412.0, 675.0, 381.0, 270.0, 348.0, 445.0, 80.72291730288738, 160.31674585625143, 152.17085764366595, 741.9800583176367, 135.99643311178394, 201.32187356430669, 222.4228322191298, 159.06481213423444, 98.63939265271549, 163.07716993715596, 874.7122665793579, 157.04856335578611, 97.50141191762262, 133.62980860317074, 504.10606229735345, 267.5136543054319, 181.19643574016584, 231.30767838205165, 116.52507064607872, 119.62517482234314, 366.0359954639818, 272.53461704160975, 142.71968807493477, 117.61326196022799, 200.11306211099944, 499.53510531903834, 111.55980462476741, 97.52908392775635, 91.49196181523784, 571.6533576580326, 509.45365188386506, 261.4008438416854, 352.67965769756324, 404.61080460002495, 380.64657128611987, 456.05045800147786, 283.1331008615567, 274.4890959644142, 1095.0115755245024, 475.25299469144244, 536.1315221063566, 956.9171514676334, 468.7910091035736, 797.4888536480636, 403.0222073846534, 367.6286783393397, 496.4631127685061, 653.7521153894606, 382.8967640896972, 466.6155945227874, 880.9222944687693, 450.4303421766214, 588.8229288209133, 699.4421351704976, 429.7716534055287, 639.936353001026, 899.8996409410468, 445.1581249825954, 403.0321842985728, 316.574564502211, 167.45779472637946, 257.71497623306914, 198.45775016394788, 320.0824669075655, 175.73402859829545, 182.3097010283414, 268.3630887278835, 617.0497009055113, 675.1677053907666, 295.71422081264603, 239.36216593440176, 637.0655568976567, 259.68153677728236, 273.81344206685804, 181.63134699241505, 221.06946626707622, 108.19483372208518, 133.0895003995974, 140.94970636666133, 106.63284123482029, 289.7933953102295, 197.76982054825126, 126.04300521581298, 112.35028021808532, 642.4098975320998, 501.5630032117051, 371.03033712712596, 290.074059485747, 458.46451493982124, 880.9222944687693, 397.8025571568676, 242.324448623758, 585.440110237543, 919.4467528654961, 593.3513664861296, 506.31438356799754, 951.314250349807, 364.3927485166189, 797.4888536480636, 653.7521153894606, 699.4421351704976, 1095.0115755245024, 899.8996409410468, 423.137412860891, 406.00009214697803, 822.9563490419024, 500.01438877696654, 424.96778113365775, 525.4506830615436, 516.2779358907504, 556.0892631729123, 496.4631127685061, 565.7864077191183, 639.936353001026, 273.51695895056497, 846.0783579767309, 340.2018835873021, 215.7112454865078, 125.49398718311377, 404.95347035370025, 530.6176080721409, 225.5852036259961, 354.05620879315853, 560.2001535494379, 248.27603215496887, 270.8072675001106, 223.84242787832764, 219.8957016509816, 1153.8804944780343, 179.69379558450296, 231.8437465203023, 242.60730175596206, 212.13476474052015, 201.3742091143239, 268.0657664869509, 124.73314447043332, 1297.946063442553, 166.98030757356344, 136.45155337942444, 626.8469591702924, 226.99422162010302, 653.5847763406725, 292.7620059505452, 278.2046424634433, 467.9254846116679, 348.93162834393127, 437.0630667105914, 412.18088738922745, 438.9702838998512, 381.64376717831766, 967.3884234171667, 358.4122679242482, 679.3560445433761, 333.75910152076386, 628.758421685016, 488.8308038311922, 782.1729040650436, 436.4855705988089, 337.5320838449469, 351.9124224569974, 389.6085792152371, 443.6532630321985, 374.0171110404061, 402.5226714306832, 372.13627608682384, 282.20092179923677, 114.83964017837398, 246.7000012565947, 239.1725958313913, 105.70363160654736, 136.49322044920487, 110.68555637245805, 141.55775754043327, 236.31151119418206, 441.11199382015184, 245.50113424149293, 387.38904606054336, 225.4771728372525, 164.76570631054662, 404.3230066856632, 128.3327751032879, 159.01459062344705, 125.26900457166538, 173.10711345301428, 108.27397066581602, 387.9893977053622, 428.9314472677671, 531.2029241681385, 195.8325957232753, 110.18918097504388, 104.65720155779935, 189.9795239137063, 358.66795285288975, 291.0700413669323, 389.37027302468687, 782.1729040650436, 384.3853950235283, 399.95072619202557, 241.44239860541353, 822.9563490419024, 372.0846401423012, 967.3884234171667, 491.51055201045966, 919.4467528654961, 623.8907089288371, 253.2467346945288, 899.8996409410468, 516.2779358907504, 514.4358370130955, 951.314250349807, 956.9171514676334, 386.9515405741979, 675.1677053907666, 617.0497009055113], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.9213, -6.2901, -6.3594, -4.7841, -6.4836, -6.1257, -6.0349, -6.3723, -6.851, -6.3556, -4.6802, -6.4001, -6.8907, -6.5779, -5.2725, -5.9074, -6.2988, -6.0637, -6.7535, -6.7288, -5.6127, -5.9135, -6.562, -6.7559, -6.2277, -5.3172, -6.8185, -6.9554, -7.0278, -5.2017, -5.319, -5.986, -5.726, -5.5977, -5.6559, -5.5036, -5.9437, -5.9803, -4.7847, -5.5405, -5.4606, -5.0592, -5.6038, -5.2198, -5.7384, -5.8059, -5.6117, -5.4682, -5.8037, -5.7165, -5.4204, -5.7426, -5.6479, -5.5838, -5.7869, -5.6817, -5.6106, -5.2357, -5.3826, -5.6307, -6.2773, -5.8788, -6.1479, -5.6765, -6.3032, -6.2817, -5.9167, -5.0891, -5.0119, -5.8487, -6.0652, -5.1026, -6.0089, -5.9657, -6.3882, -6.1977, -6.9221, -6.7161, -6.6801, -6.9606, -5.9658, -6.3502, -6.8077, -6.9316, -5.1882, -5.4409, -5.7517, -6.0006, -5.5683, -4.9687, -5.7325, -6.1866, -5.3927, -5.0135, -5.4056, -5.5631, -5.0615, -5.8316, -5.2979, -5.4371, -5.4038, -5.1343, -5.2798, -5.7519, -5.7978, -5.4779, -5.7073, -5.7793, -5.7107, -5.718, -5.6969, -5.7553, -5.7439, -5.7444, -5.3471, -4.2194, -5.1332, -5.5943, -6.1403, -4.9748, -4.7092, -5.5649, -5.1237, -4.6689, -5.4979, -5.4156, -5.6244, -5.6591, -4.0027, -5.8661, -5.6188, -5.5745, -5.709, -5.7613, -5.4823, -6.2481, -3.908, -5.9615, -6.1645, -4.6434, -5.6595, -4.6113, -5.4175, -5.4845, -4.9788, -5.2658, -5.095, -5.1492, -5.0975, -5.2312, -4.5078, -5.2967, -4.8198, -5.3927, -5.0424, -5.2245, -5.0301, -5.2924, -5.4161, -5.4061, -5.385, -5.4117, -5.1596, -5.0949, -5.3388, -5.6207, -6.5388, -5.8379, -5.8745, -6.6951, -6.4406, -6.6682, -6.423, -5.9129, -5.2901, -5.8769, -5.4224, -5.9651, -6.3055, -5.4181, -6.5657, -6.3531, -6.5983, -6.2849, -6.7542, -5.4899, -5.3955, -5.1882, -6.1925, -6.7727, -6.8281, -6.24, -5.6075, -5.8418, -5.5656, -4.9488, -5.6362, -5.6086, -6.0402, -5.0724, -5.7168, -5.0539, -5.5786, -5.1688, -5.4304, -6.0385, -5.2961, -5.6314, -5.6411, -5.3457, -5.379, -5.798, -5.7916, -5.8043], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1335, 1.0785, 1.0614, 1.0523, 1.0495, 1.0151, 1.0063, 1.0042, 1.0033, 0.9959, 0.9917, 0.9891, 0.9752, 0.9728, 0.9504, 0.9492, 0.9474, 0.9383, 0.9342, 0.9326, 0.9303, 0.9245, 0.9229, 0.9225, 0.9192, 0.9149, 0.9127, 0.9102, 0.9017, 0.8955, 0.8935, 0.8937, 0.8542, 0.8452, 0.848, 0.8196, 0.8562, 0.8505, 0.6626, 0.7414, 0.7008, 0.5229, 0.6919, 0.5444, 0.7084, 0.7328, 0.6266, 0.4949, 0.6943, 0.5838, 0.2444, 0.5929, 0.4197, 0.3116, 0.5956, 0.3027, 0.0329, 1.1116, 1.0642, 1.0575, 1.0478, 1.0151, 1.0073, 1.0007, 0.9736, 0.9584, 0.9368, 0.9317, 0.9189, 0.9077, 0.9026, 0.8863, 0.8774, 0.8676, 0.8556, 0.8496, 0.8397, 0.8387, 0.8173, 0.8158, 0.8108, 0.8084, 0.8014, 0.7926, 0.7923, 0.7872, 0.7777, 0.7751, 0.7496, 0.6961, 0.7273, 0.7689, 0.6807, 0.6085, 0.6544, 0.6555, 0.5264, 0.7159, 0.4664, 0.526, 0.4917, 0.3129, 0.3637, 0.6462, 0.6416, 0.255, 0.5238, 0.6144, 0.4708, 0.4811, 0.4279, 0.4829, 0.3637, 0.24, 1.4873, 1.4857, 1.4831, 1.4775, 1.4732, 1.4672, 1.4625, 1.4621, 1.4526, 1.4485, 1.4333, 1.4287, 1.4105, 1.3935, 1.3922, 1.3884, 1.3809, 1.3798, 1.3796, 1.3793, 1.3722, 1.3715, 1.3692, 1.3664, 1.3653, 1.3617, 1.3613, 1.352, 1.3489, 1.333, 1.3186, 1.3251, 1.2707, 1.2751, 1.2638, 1.27, 1.0633, 1.2674, 1.1048, 1.2426, 0.9596, 1.0293, 0.7536, 1.0746, 1.208, 1.1763, 1.0956, 0.9391, 1.3619, 1.3531, 1.1877, 1.1824, 1.1635, 1.0997, 1.094, 1.09, 1.0889, 1.0709, 1.0701, 1.0677, 1.0663, 1.0656, 1.0639, 1.0624, 1.0357, 1.0254, 1.0254, 1.0237, 1.017, 1.0069, 1.0069, 0.9949, 0.989, 0.9824, 0.976, 0.9708, 0.967, 0.9588, 0.9558, 0.9304, 0.9156, 0.8349, 0.858, 0.8458, 0.9189, 0.6604, 0.8098, 0.5173, 0.6697, 0.4532, 0.5793, 0.8729, 0.3474, 0.5678, 0.5616, 0.2422, 0.2031, 0.6895, 0.1392, 0.2165]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4], \"Freq\": [0.05580166135447985, 0.011160332270895969, 0.8007538404367859, 0.13392398725075164, 0.7380385999610982, 0.11156397441272416, 0.11156397441272416, 0.03432737674237666, 0.09922008695605801, 0.06732791614875365, 0.16654800310481166, 0.6697355869533916, 0.12461028110320978, 0.6141506711515339, 0.008900734364514985, 0.2581212965709345, 0.1397531485849912, 0.13706558803527982, 0.2606933733220028, 0.4622604145503555, 0.07527854045848988, 0.36245223183717346, 0.027880940910551804, 0.5353140654825946, 0.12015089306687253, 0.24710278008092654, 0.03627196771830114, 0.596220469369575, 0.8938582591666971, 0.10428346356944801, 0.06110609747367475, 0.06110609747367475, 0.8554853646314465, 0.021566857931885206, 0.00598873013549486, 0.02395492054197944, 0.8863320600532393, 0.08384222189692804, 0.790759126778268, 0.19262081293316785, 0.010137937522798308, 0.3776372138562616, 0.4279888423704298, 0.05394817340803737, 0.14206352330783173, 0.5281874646716284, 0.35367618779774235, 0.006980451074955441, 0.11168721719928705, 0.3388492172650382, 0.515333184590579, 0.021178076079064887, 0.12236221734570824, 0.2272013664591093, 0.6700514875234749, 0.10397350668467714, 0.13146596345146908, 0.6269915179993141, 0.030338299258031328, 0.2123680948062193, 0.0022910264791299122, 0.15120774762257422, 0.6598156259894148, 0.18786417128865282, 0.12190912456930886, 0.1828636868539633, 0.03483117844837396, 0.6530845959070117, 0.71056512925443, 0.2767670807316979, 0.0019628870973879284, 0.01177732258432757, 0.08665155175192374, 0.09820509198551357, 0.25417788513897627, 0.5603467013291068, 0.09183530613846294, 0.233120392505329, 0.07770679750177634, 0.6004616170591808, 0.10841522953202562, 0.22586506152505337, 0.07227681968801708, 0.5962837624261409, 0.15608404279161828, 0.631430900384274, 0.09932620904921163, 0.1135156674848133, 0.15933169132544195, 0.7397542811538377, 0.028452087736686064, 0.07397542811538377, 0.08007997624556969, 0.052623984389945797, 0.8030877617769989, 0.06406398099645576, 0.49011557508472914, 0.18287894592713774, 0.07524162346716524, 0.25185043410537256, 0.9247576608332602, 0.07594628132447064, 0.0017850762690156056, 0.9585859564613802, 0.03927167791834332, 0.7707861073562597, 0.07483360265594755, 0.14218384504630033, 0.007483360265594754, 0.04218025423847075, 0.8088684048083215, 0.05954859421901753, 0.08932289132852629, 0.5856771837745243, 0.36371672240774594, 0.016786925649588273, 0.033573851299176546, 0.7246737939845114, 0.2582401089060828, 0.008007445237397916, 0.008007445237397916, 0.8705833131330711, 0.12852196538344107, 0.013789581898813475, 0.6067416035477929, 0.38266089769207395, 0.021067994978237074, 0.7082087542684309, 0.01620614998325929, 0.2544365547371708, 0.09496710794851249, 0.12063389388054288, 0.6750364700123995, 0.11036717950773073, 0.008473230875475525, 0.025419692626426574, 0.9631239095123847, 0.00564882058365035, 0.7692196300025511, 0.041025046933469395, 0.14358766426714287, 0.05128130866683674, 0.19441965819477397, 0.4012114764564881, 0.16790788662275932, 0.23683849270999738, 0.5207712790836291, 0.3407515776720042, 0.034289466935547595, 0.10286840080664278, 0.194043284059292, 0.2400009039680717, 0.020425608848346526, 0.5463850366932695, 0.8411597462356022, 0.13800277086677848, 0.019714681552396928, 0.08062169397154934, 0.7608672368564968, 0.15620453206987683, 0.39745961248421796, 0.45607775677145873, 0.007148554181370827, 0.1401116619548682, 0.3608719120847946, 0.6120866133150936, 0.025918977111062596, 0.9708083530295991, 0.026597489124098605, 0.10579256115651929, 0.20735341986677783, 0.0888657513714762, 0.5966700449227689, 0.7997143934217015, 0.15894944465524502, 0.02980302087285844, 0.01490151043642922, 0.34698503361193267, 0.6283242500540402, 0.018755947762807174, 0.007732170048311964, 0.38403111239949417, 0.051547800322079756, 0.5541388534623574, 0.683339667428925, 0.17012605828106017, 0.04820238317963372, 0.09924020066395177, 0.5824024147348504, 0.21154527171983356, 0.08879678072190544, 0.11752515095546309, 0.2644693976662833, 0.29171775985008214, 0.07693655204837332, 0.36705146706411435, 0.4772451096607646, 0.4711265826138318, 0.02141484466426508, 0.0305926352346644, 0.06210830289668578, 0.0869516240553601, 0.05465530654908349, 0.794986277077578, 0.12942565692807254, 0.5122645749001863, 0.03589114855988566, 0.323020337038971, 0.07498067679830399, 0.7591793525828279, 0.06873228706511199, 0.09685004086447598, 0.37576445657447033, 0.5317421555299109, 0.01181649234510913, 0.08035214794674209, 0.02350801647217167, 0.05129021775746546, 0.8420144081850579, 0.08334660385588137, 0.009893080368562256, 0.1706556363576989, 0.24485373912191583, 0.5713253912844702, 0.03183327344483704, 0.9095220984239153, 0.05911893639755449, 0.6777940994667981, 0.2837277625674969, 0.0026271089126620084, 0.03415241586460611, 0.014813406604324064, 0.10369384623026845, 0.7525210554996624, 0.12739529679718695, 0.07568330319792413, 0.3027332127916965, 0.009460412899740516, 0.6149268384831336, 0.7260679621342504, 0.20616744603812048, 0.026891406004972238, 0.044819010008287065, 0.9465271293417391, 0.05236107524018131, 0.7505666402567811, 0.15452842593521962, 0.09933970238692691, 0.20888848412953748, 0.6893319976274737, 0.066844314921452, 0.033422157460726, 0.04789692406765673, 0.1436907722029702, 0.23150179966034085, 0.5667802681339379, 0.22077980670338998, 0.5359387674173894, 0.04718957700530473, 0.19549967616483388, 0.003101132830805347, 0.6522716054127247, 0.34422574421939356, 0.1625200199506376, 0.30253726790811003, 0.05500677598329273, 0.4775588278549506, 0.728701144199495, 0.2522427037613637, 0.007006741771148991, 0.007006741771148991, 0.21181164869425403, 0.1914451440121142, 0.5947019367184825, 0.14125372122723115, 0.12327597488921992, 0.2234377044867111, 0.5136498953717497, 0.048098388739194045, 0.16147316219586572, 0.26797673726122395, 0.522211077739821, 0.8545582638188124, 0.11227772809298264, 0.03118825780360629, 0.7338517292629457, 0.216486260132569, 0.0036692586463147286, 0.047700362402091474, 0.4415588919416508, 0.305694617498066, 0.008491517152724054, 0.24285739056790795, 0.04494259461885212, 0.041946421644261975, 0.7820011463680269, 0.1318316108819662, 0.7312100571539432, 0.15304396545082533, 0.051014655150275104, 0.05951709767532096, 0.6600146863552203, 0.22585220164314848, 0.017541918574225126, 0.09648055215823818, 0.010325537184587447, 0.10583675614202134, 0.28653365687230165, 0.5962997724099252, 0.021497501087836716, 0.08330281671536728, 0.22303657378630593, 0.6744840966308769, 0.17618104214872296, 0.6551732504905635, 0.09910183620865666, 0.0660678908057711, 0.7356311088421806, 0.15882944395456175, 0.05015666651196687, 0.05015666651196687, 0.02183507356929238, 0.050948504995015555, 0.8054716027783412, 0.12130596427384657, 0.1471648300743111, 0.47197863359546915, 0.11878304141712254, 0.26174316206073905, 0.7376323731707096, 0.1967019661788559, 0.02458774577235699, 0.04371154803974576, 0.7435983154692645, 0.20319256294799667, 0.017292984080680567, 0.03890921418153128, 0.526163488131686, 0.3885173435571521, 0.0288612883785313, 0.0577225767570626, 0.16981275963467302, 0.24022292826368377, 0.07455194325424669, 0.513580053529255, 0.004785857147605633, 0.01595285715868544, 0.8790024294435679, 0.09890771438384974, 0.9935277148848087, 0.005878862218253306, 0.11007324644903602, 0.8468900798221751, 0.01572474949271943, 0.029203106200764658, 0.7295875564535422, 0.0899491507956422, 0.07495762566303515, 0.10494067592824922, 0.013662975108442521, 0.04782041287954882, 0.8675989193861, 0.07514636309643387, 0.0008666408738041428, 0.010399690485649713, 0.9065063539991334, 0.0831975238851977, 0.02770749037420452, 0.1385374518710226, 0.26783907361731035, 0.5633856376088252, 0.0732860839787838, 0.8794330077454056, 0.04397165038727028, 0.05932523026927444, 0.05727953267378222, 0.6300748594116043, 0.2536665018410355, 0.7213748474787629, 0.18580867283543892, 0.021859843862992816, 0.08743937545197127, 0.3712018665587228, 0.5596407345977075, 0.012486912942342356, 0.05789386909631456, 0.002673674466973697, 0.12031535101381638, 0.07486288507526352, 0.8021023400921092, 0.020609437406914836, 0.020609437406914836, 0.894449583460104, 0.06182831222074451, 0.7831972313006729, 0.1209816861358763, 0.031837285825230606, 0.07004202881550733, 0.6771939772366204, 0.3188249016916936, 0.004943021731654164, 0.19004103821339344, 0.711722319583493, 0.007452589733858566, 0.08943107680630279, 0.008505918944728358, 0.3596788582342277, 0.23452033661893898, 0.3973479278465961, 0.13854082937063228, 0.6148722202404466, 0.012453108258034362, 0.2334957798381443, 0.0011819236251253955, 0.9951796923555831, 0.002363847250250791, 0.22370138421204558, 0.6064194150326536, 0.04851355320261229, 0.12128388300653073, 0.1726666883949453, 0.6765394790747403, 0.026684851842855184, 0.12400607621091528, 0.26412670582825754, 0.16350700836987372, 0.572274529294558, 0.6038701904400474, 0.27201359929731866, 0.09792489574703472, 0.02448122393675868, 0.01669506724058938, 0.9015336309918265, 0.07791031378941711, 0.08790648745249856, 0.13073272492935684, 0.5770271996881957, 0.20736914988794533, 0.3318229046676232, 0.5756624634006493, 0.010055239535382522, 0.08044191628306017, 0.0568323216906159, 0.036941009098900336, 0.7302953337244144, 0.1761801972409093, 0.2733989527268786, 0.5295565300565667, 0.10098519875497318, 0.0985221451268031, 0.24668377994940954, 0.07525945828965037, 0.066897296257467, 0.614618909365478, 0.41227182689732567, 0.037650395150440705, 0.5478132494389122, 0.6851901081493822, 0.28608452969123693, 0.021191446643795325, 0.010595723321897663, 0.7831146608687163, 0.16462556374466444, 0.021721428549643224, 0.03086729320212458, 0.03299789173435239, 0.04242586080131022, 0.8956570613609935, 0.03299789173435239, 0.7849044722159857, 0.1533016547296847, 0.018396198567562163, 0.04292446332431171, 0.7119699281876176, 0.2484022845273752, 0.026239677943032592, 0.013994494902950716, 0.7921299394216043, 0.16974212987605808, 0.006286745550965114, 0.031433727754825565, 0.04343590061790299, 0.20533334837554143, 0.2566666854694268, 0.4896410615109065, 0.020061236733462044, 0.04585425539077039, 0.8483037247292522, 0.08597672885769447, 0.20287099973276085, 0.6461817028524975, 0.08265114803927294, 0.06762366657758695, 0.36540060977998945, 0.4472351213452996, 0.00761251270374978, 0.18079717671405726, 0.6812656777602684, 0.19308599423151993, 0.12386648686550335, 0.30003345675041554, 0.40115584402555554, 0.007778645175010772, 0.2911435765504032, 0.33154147168827613, 0.5889223510252274, 0.021811938926860272, 0.05671104120983671, 0.10421826097474818, 0.7295278268232372, 0.10421826097474818, 0.06582205956299884, 0.9981099564994125, 0.8329064818820755, 0.11455833488669323, 0.001347745116314038, 0.052562059536247485, 0.5905381778946178, 0.27293781331263844, 0.049625056965934264, 0.08684384969038497, 0.3907192803033342, 0.1574540383311944, 0.09136221977242143, 0.35961724804038225, 0.1996566251362069, 0.2541084319915361, 0.5445180685532917, 0.7957816121396231, 0.1438701219687454, 0.04046347180370965, 0.017983765246093176, 0.7177346200837051, 0.18456033087866705, 0.020506703430963006, 0.07177346200837052, 0.03158813474394011, 0.8023386224960788, 0.10424084465500236, 0.06317626948788022, 0.016292248447566864, 0.6990855697501418, 0.048876745342700596, 0.23549704574210287, 0.01975535607340894, 0.9778901256337426, 0.0024694195091761175, 0.5802159058470872, 0.3562355010164101, 0.040529787540789175, 0.023464613839404257, 0.7518259119376389, 0.1547293433539204, 0.02578822389232007, 0.06744612402606788, 0.361989582825257, 0.46998647493886964, 0.03599896403787087, 0.1299962590256448, 0.003880255678644116, 0.7682906243715351, 0.011640767035932349, 0.2134140623254264, 0.2848654887474606, 0.6646861404107414, 0.05112970310851857, 0.024051345877126658, 0.04008557646187776, 0.8898997974536863, 0.048102691754253316, 0.2895017619605639, 0.6513789644112686, 0.0045234650306338105, 0.05428158036760572, 0.1478813678026293, 0.6469809841365033, 0.08318326938897899, 0.12939619682730066, 0.0012784896981254193, 0.04730411883064051, 0.4781551470989068, 0.4730411883064051, 0.049376436481667764, 0.5372156289205453, 0.18960551608960421, 0.2231814928971383, 0.8860152454639337, 0.11325586181147675, 0.3937891617162058, 0.35472277662531243, 0.028127797265443275, 0.22345972271991046, 0.9043280698849181, 0.037164167255544577, 0.024776111503696383, 0.037164167255544577, 0.12694080066247648, 0.6188364032295729, 0.09520560049685736, 0.15074220078669082, 0.08585133677615421, 0.38503023766275224, 0.044226446218018835, 0.48388935273832373, 0.005263725160476907, 0.4316254631591064, 0.026318625802384536, 0.5368999663686445, 0.02544697525819446, 0.2815071637937762, 0.5884613028457469, 0.10496877294005215, 0.12921514649044924, 0.2842733222789883, 0.18090120508662896, 0.40831986290981964, 0.6102013101217431, 0.18726867793391427, 0.002104142448695666, 0.20199767507478392, 0.058610969641361435, 0.25642299218095627, 0.07326371205170179, 0.6080888100291248, 0.041801577594150034, 0.7942299742888507, 0.02985826971010717, 0.13137638672447155, 0.07013017518522764, 0.13246810868320774, 0.22597500893017794, 0.5688336431690686, 0.7115508782085221, 0.1912771177979898, 0.02295325413575878, 0.08033638947515573, 0.02060775069633772, 0.19871759600039945, 0.6800557729791449, 0.10156677128909306, 0.5438470513838503, 0.45119162781474986, 0.00402849667691741, 0.002014248338458705, 0.37140288778594255, 0.6024980179638624, 0.004126698753177139, 0.020633493765885698, 0.007968509268423006, 0.9801266400160297, 0.007968509268423006, 0.9874311351714976, 0.009271653851375565, 0.003730427846513847, 0.04476513415816616, 0.8878418274702955, 0.05968684554422155, 0.03719807579686608, 0.6898552238691528, 0.016908216271302765, 0.257004887323802, 0.8309041451632652, 0.16176894861585692, 0.007353134027993496, 0.03648155636058966, 0.1297122003932077, 0.21483583190125022, 0.6161329518677365, 0.24698625416223222, 0.5708126762860478, 0.03842008398079168, 0.14270316907151195, 0.2760587414849756, 0.6280336368783196, 0.006901468537124391, 0.08971909098261707, 0.17238776599361258, 0.45130729748889586, 0.01355858833657627, 0.3622080027056804, 0.02643239090923462, 0.01321619545461731, 0.8810796969744874, 0.07929717272770387, 0.5634643631090946, 0.3808178920850769, 0.010958788261441062, 0.04383515304576425, 0.047445748117414685, 0.030192748801991163, 0.8971559644020232, 0.025879498973135285, 0.001884596336019146, 0.9724517093858793, 0.026384348704268045, 0.02049739980257073, 0.5500135613689813, 0.17764413162227966, 0.2528012642317057, 0.751363516460022, 0.2429782515915494, 0.007476253895124597, 0.16993827554883442, 0.18207672380232262, 0.06676146539418495, 0.5765762920406883, 0.11466005034897406, 0.2675401174809395, 0.07644003356598271, 0.5446352391576268, 0.5003204724113687, 0.443893351462718, 0.0012539360210811245, 0.05391924890648835, 0.03548031004351084, 0.01774015502175542, 0.35036806167966955, 0.5942951932288066, 0.02564512364404254, 0.10258049457617016, 0.31939835811216616, 0.5525358457852801, 0.13631446919286933, 0.295008925865165, 0.16683263393754155, 0.40080523031336207, 0.0036926630855635793, 0.022155978513381476, 0.9416290868187127, 0.03323396777007222, 0.0026202445474047638, 0.04978464640069051, 0.8017948315058577, 0.14673369465466676, 0.002278058530786892, 0.7973204857754123, 0.19819109217845962], \"Term\": [\"achieve\", \"achieve\", \"achieve\", \"achieve\", \"acknowledge\", \"acknowledge\", \"acknowledge\", \"acknowledge\", \"activity\", \"activity\", \"activity\", \"activity\", \"advise\", \"advise\", \"advise\", \"advise\", \"agency\", \"agency\", \"agency\", \"agency\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agriculture\", \"agriculture\", \"agriculture\", \"agriculture\", \"ahead\", \"ahead\", \"ally\", \"ally\", \"ally\", \"ally\", \"americans\", \"americans\", \"americans\", \"americans\", \"amicable\", \"amicable\", \"amicable\", \"annual\", \"annual\", \"annual\", \"annual\", \"appear\", \"appear\", \"appear\", \"appear\", \"appoint\", \"appoint\", \"appoint\", \"appoint\", \"appointment\", \"appointment\", \"appointment\", \"approval\", \"approval\", \"approval\", \"approval\", \"area\", \"area\", \"area\", \"area\", \"armament\", \"armament\", \"armament\", \"armament\", \"article\", \"article\", \"article\", \"article\", \"assist\", \"assist\", \"assist\", \"assist\", \"association\", \"association\", \"association\", \"association\", \"attitude\", \"attitude\", \"attitude\", \"attitude\", \"attorney\", \"attorney\", \"attorney\", \"attorney\", \"award\", \"award\", \"award\", \"award\", \"back\", \"back\", \"back\", \"back\", \"bank\", \"bank\", \"bank\", \"bank\", \"basic\", \"basic\", \"billion\", \"billion\", \"billion\", \"blessing\", \"blessing\", \"blessing\", \"blessing\", \"bond\", \"bond\", \"bond\", \"bond\", \"britain\", \"britain\", \"britain\", \"britain\", \"british\", \"british\", \"british\", \"british\", \"budget\", \"budget\", \"bureau\", \"bureau\", \"bureau\", \"cent\", \"cent\", \"cent\", \"cent\", \"century\", \"century\", \"century\", \"century\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"cherish\", \"cherish\", \"cherish\", \"cherish\", \"class\", \"class\", \"class\", \"class\", \"coast\", \"coast\", \"coast\", \"coast\", \"combination\", \"combination\", \"combination\", \"combination\", \"commence\", \"commence\", \"commence\", \"commend\", \"commend\", \"commend\", \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"commissioner\", \"commissioner\", \"commissioner\", \"commitment\", \"commitment\", \"committee\", \"committee\", \"committee\", \"committee\", \"communicate\", \"communicate\", \"communicate\", \"communicate\", \"concur\", \"concur\", \"concur\", \"conference\", \"conference\", \"conference\", \"conference\", \"consequence\", \"consequence\", \"consequence\", \"consequence\", \"constitutional\", \"constitutional\", \"constitutional\", \"constitutional\", \"construction\", \"construction\", \"construction\", \"construction\", \"convention\", \"convention\", \"convention\", \"convention\", \"corporation\", \"corporation\", \"corporation\", \"corporation\", \"court\", \"court\", \"court\", \"court\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"currency\", \"currency\", \"currency\", \"currency\", \"cut\", \"cut\", \"cut\", \"cut\", \"deal\", \"deal\", \"deal\", \"deal\", \"decade\", \"decade\", \"decade\", \"deem\", \"deem\", \"deem\", \"deem\", \"deficit\", \"deficit\", \"deficit\", \"deficit\", \"definite\", \"definite\", \"definite\", \"definite\", \"deliberation\", \"deliberation\", \"deliberation\", \"deliberation\", \"democracy\", \"democracy\", \"derive\", \"derive\", \"derive\", \"diplomatic\", \"diplomatic\", \"diplomatic\", \"diplomatic\", \"disaster\", \"disaster\", \"disaster\", \"disaster\", \"district\", \"district\", \"district\", \"district\", \"economic\", \"economic\", \"economic\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficiency\", \"embarrassment\", \"embarrassment\", \"embarrassment\", \"embarrassment\", \"employee\", \"employee\", \"employee\", \"employment\", \"employment\", \"employment\", \"employment\", \"enact\", \"enact\", \"enact\", \"enact\", \"entertain\", \"entertain\", \"entertain\", \"execution\", \"execution\", \"execution\", \"execution\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"expand\", \"expand\", \"expand\", \"expand\", \"expose\", \"expose\", \"expose\", \"expose\", \"extent\", \"extent\", \"extent\", \"extent\", \"farm\", \"farm\", \"farm\", \"farm\", \"farmer\", \"farmer\", \"farmer\", \"farmer\", \"february\", \"february\", \"february\", \"february\", \"feeling\", \"feeling\", \"feeling\", \"feeling\", \"fight\", \"fight\", \"fight\", \"fight\", \"fiscal\", \"fiscal\", \"fiscal\", \"fiscal\", \"france\", \"france\", \"france\", \"france\", \"french\", \"french\", \"french\", \"french\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"function\", \"function\", \"function\", \"function\", \"get\", \"get\", \"get\", \"get\", \"goal\", \"goal\", \"gold\", \"gold\", \"gold\", \"gold\", \"happy\", \"happy\", \"happy\", \"happy\", \"hard\", \"hard\", \"hard\", \"hard\", \"help\", \"help\", \"help\", \"help\", \"highway\", \"highway\", \"highway\", \"highway\", \"historic\", \"historic\", \"historic\", \"income\", \"income\", \"income\", \"income\", \"inconvenience\", \"inconvenience\", \"inconvenience\", \"inconvenience\", \"indian\", \"indian\", \"indian\", \"indian\", \"industrial\", \"industrial\", \"industrial\", \"industrial\", \"inflation\", \"inflation\", \"inflation\", \"inflation\", \"inform\", \"inform\", \"inform\", \"inform\", \"intercourse\", \"intercourse\", \"intercourse\", \"interior\", \"interior\", \"interior\", \"interior\", \"international\", \"international\", \"international\", \"international\", \"island\", \"island\", \"island\", \"island\", \"job\", \"job\", \"job\", \"july\", \"july\", \"july\", \"july\", \"june\", \"june\", \"june\", \"june\", \"lack\", \"lack\", \"lack\", \"late\", \"late\", \"late\", \"late\", \"leadership\", \"leadership\", \"leadership\", \"low\", \"low\", \"low\", \"low\", \"mail\", \"mail\", \"mail\", \"mail\", \"major\", \"major\", \"major\", \"major\", \"march\", \"march\", \"march\", \"march\", \"merely\", \"merely\", \"merely\", \"merely\", \"method\", \"method\", \"method\", \"mexican\", \"mexican\", \"mexican\", \"mexican\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"middle\", \"middle\", \"middle\", \"middle\", \"militia\", \"militia\", \"militia\", \"militia\", \"minister\", \"minister\", \"minister\", \"minister\", \"mode\", \"mode\", \"mode\", \"mode\", \"modern\", \"modern\", \"modern\", \"modern\", \"move\", \"move\", \"move\", \"move\", \"native\", \"native\", \"native\", \"native\", \"naval\", \"naval\", \"naval\", \"naval\", \"navigation\", \"navigation\", \"navigation\", \"navy\", \"navy\", \"navy\", \"navy\", \"note\", \"note\", \"note\", \"note\", \"november\", \"november\", \"november\", \"november\", \"nuclear\", \"object\", \"object\", \"object\", \"object\", \"occasion\", \"occasion\", \"occasion\", \"occasion\", \"ought\", \"ought\", \"ought\", \"ought\", \"outside\", \"outside\", \"outside\", \"paper\", \"paper\", \"paper\", \"paper\", \"patriotism\", \"patriotism\", \"patriotism\", \"patriotism\", \"pension\", \"pension\", \"pension\", \"pension\", \"per\", \"per\", \"per\", \"per\", \"percent\", \"percent\", \"percent\", \"port\", \"port\", \"port\", \"port\", \"portion\", \"portion\", \"portion\", \"portion\", \"post\", \"post\", \"post\", \"post\", \"postal\", \"postal\", \"postal\", \"postal\", \"postmaster\", \"postmaster\", \"postmaster\", \"poverty\", \"poverty\", \"poverty\", \"poverty\", \"precede\", \"precede\", \"precede\", \"precede\", \"prior\", \"prior\", \"prior\", \"prior\", \"problem\", \"problem\", \"problem\", \"problem\", \"product\", \"product\", \"product\", \"product\", \"program\", \"program\", \"property\", \"property\", \"property\", \"property\", \"providence\", \"providence\", \"providence\", \"providence\", \"quite\", \"quite\", \"quite\", \"quite\", \"railroad\", \"railroad\", \"railroad\", \"railroad\", \"railway\", \"railway\", \"railway\", \"railway\", \"reform\", \"reform\", \"reform\", \"reform\", \"relief\", \"relief\", \"relief\", \"relief\", \"render\", \"render\", \"render\", \"render\", \"reorganization\", \"reorganization\", \"reorganization\", \"reorganization\", \"reservation\", \"reservation\", \"reservation\", \"reservation\", \"safeguard\", \"safeguard\", \"safeguard\", \"safeguard\", \"satisfaction\", \"satisfaction\", \"satisfaction\", \"satisfaction\", \"school\", \"school\", \"school\", \"school\", \"spain\", \"spain\", \"spain\", \"spain\", \"spanish\", \"spanish\", \"spanish\", \"spanish\", \"speaker\", \"speaker\", \"speaker\", \"spending\", \"spending\", \"start\", \"start\", \"start\", \"start\", \"statute\", \"statute\", \"statute\", \"statute\", \"stipulation\", \"stipulation\", \"stipulation\", \"study\", \"study\", \"study\", \"study\", \"suggest\", \"suggest\", \"suggest\", \"suggest\", \"suggestion\", \"suggestion\", \"suggestion\", \"suggestion\", \"tariff\", \"tariff\", \"tariff\", \"tariff\", \"tell\", \"tell\", \"tell\", \"tell\", \"territory\", \"territory\", \"territory\", \"territory\", \"threat\", \"threat\", \"threat\", \"threat\", \"today\", \"today\", \"today\", \"total\", \"total\", \"total\", \"total\", \"tribe\", \"tribe\", \"tribe\", \"undertake\", \"undertake\", \"undertake\", \"undertake\", \"undertaken\", \"undertaken\", \"undertaken\", \"undertaken\", \"vessel\", \"vessel\", \"vessel\", \"vessel\", \"veteran\", \"veteran\", \"veteran\", \"veteran\", \"wage\", \"wage\", \"wage\", \"wage\", \"water\", \"water\", \"water\", \"water\", \"weapon\", \"weapon\", \"weapon\", \"weapon\", \"woman\", \"woman\", \"woman\", \"woman\", \"worker\", \"worker\", \"worker\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 1, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el16147511402887874090245033217064\", ldavis_el16147511402887874090245033217064_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el16147511402887874090245033217064\", ldavis_el16147511402887874090245033217064_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el16147511402887874090245033217064\", ldavis_el16147511402887874090245033217064_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df_speeches['word'])\n",
    "dictionary.filter_extremes(no_above=0.6,no_below=60)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df_speeches['word']]\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=dictionary,num_topics=4, passes=20,random_state = 1)\n",
    "\n",
    "vis_data1 = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "When I first ran the model with no filtering of common words, all topics seemed to be centered around words like \"government\", \"american\", \"congress\", etc. which is typical of any political speech. However, after filtering and removing common words, the corpus seemed to split into around 4 topics: one I found that when splitting the corpus into 4 distinct topics. Topic one's most common words are \"mexico\", \"territory\", \"british\", \"indian\", \"vessel\", etc. most of which are related to international trade/relations. The next topic also seems to be related to international relations, but more on the economic side with words like \"gold\", \"fiscal\", and \"cent\" thrown into the mix as well. The third topic is the most distinct from the other three, with a heavy focus on internal economic problems and words like program, help, job, budget, etc. The last topic again seems to focus on fiscal, specifically, down economy issues with head words being problem, corporation, bank, and agriculture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part II Prediction (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you are asked to predict the president's political party (Republican/Democratic) using their speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pres_to_party(name):\n",
    "    \"\"\"\n",
    "    Determines the political party affiliation of a U.S. President based on their name.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): The full name of a U.S. President.\n",
    "    \"\"\"\n",
    "    \n",
    "    republican = ['Abraham Lincoln', 'Ulysses S. Grant', 'Rutherford B. Hayes', 'Garfield', 'Chester A. Arthur', \n",
    "                  'Benjamin Harrison', 'William McKinley', 'Theodore Roosevelt', \n",
    "                  'William Howard Taft', 'Warren G. Harding', 'Calvin Coolidge', 'Herbert Hoover', 'Dwight D. Eisenhower', \n",
    "                  'Richard M. Nixon', 'Gerald R. Ford', 'Ronald Reagan', 'George Bush', \n",
    "                  'George W. Bush', 'Donald J. Trump']\n",
    "    if name in republican:\n",
    "        return 'Republican'\n",
    "    \n",
    "    democratic = ['Andrew Jackson', 'Martin Van Buren', 'James K. Polk', 'Franklin Pierce', \n",
    "                  'James Buchanan', 'Grover Cleveland', 'Woodrow Wilson', 'Franklin D. Roosevelt', \n",
    "                  'Harry S Truman', 'John F. Kennedy', 'Lyndon B. Johnson', 'Jimmy Carter', 'William J. Clinton', 'Barack Obama','Joseph R. Biden']\n",
    "    if name in democratic:\n",
    "        return 'Democratic'\n",
    "    \n",
    "    whig = ['William Henry Harrison', 'Zachary Taylor', 'Millard Fillmore']\n",
    "    if name in whig:\n",
    "        return 'Whig'\n",
    "    \n",
    "    national_union = ['Andrew Johnson']\n",
    "    if name in national_union:\n",
    "        return 'National Union'\n",
    "    \n",
    "    \n",
    "    unaffiliated = ['George Washington', 'John Tyler']\n",
    "    if name in unaffiliated:\n",
    "        return 'Unaffiliated'\n",
    "    \n",
    "    federalist = ['John Adams']\n",
    "    if name in federalist:\n",
    "        return 'Federalist'\n",
    "    \n",
    "    democratic_republican = ['Thomas Jefferson', 'James Madison', 'James Monroe', 'John Quincy Adams']\n",
    "    if name in democratic_republican:\n",
    "        return 'Democratic-Republican'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>word</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "      <td>[senate, house, representative, give, pleasure...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "      <td>[deliver, person, joint, session, mr, presiden...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "      <td>[since, close, last, congress, nation, lose, p...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Thank you very much. Mr. Speaker, Mr. Vice Pre...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[thank, much, mr, speaker, mr, vice, president...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[mr, speaker, mr, vice, president, member, con...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>Madame Speaker.Madame Vice President.No presid...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[madame, speakermadame, vice, presidentno, pre...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                president                                               text  \\\n",
       "0            James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1        William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2    Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3         Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4           James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "..                    ...                                                ...   \n",
       "229       Donald J. Trump  Thank you very much. Mr. Speaker, Mr. Vice Pre...   \n",
       "230       Donald J. Trump  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "231       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "232       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "233       Joseph R. Biden  Madame Speaker.Madame Vice President.No presid...   \n",
       "\n",
       "     year                                               word  \\\n",
       "0    1821  [fellow, citizen, senate, house, representativ...   \n",
       "1    1897  [senate, house, representative, give, pleasure...   \n",
       "2    1960  [deliver, person, joint, session, mr, presiden...   \n",
       "3    1923  [since, close, last, congress, nation, lose, p...   \n",
       "4    1816  [fellow, citizen, senate, house, representativ...   \n",
       "..    ...                                                ...   \n",
       "229  2017  [thank, much, mr, speaker, mr, vice, president...   \n",
       "230  2018  [mr, speaker, mr, vice, president, member, con...   \n",
       "231  2019  [madam, speaker, mr, vice, president, member, ...   \n",
       "232  2020  [madam, speaker, mr, vice, president, member, ...   \n",
       "233  2021  [madame, speakermadame, vice, presidentno, pre...   \n",
       "\n",
       "                     party  \n",
       "0    Democratic-Republican  \n",
       "1               Republican  \n",
       "2               Republican  \n",
       "3               Republican  \n",
       "4    Democratic-Republican  \n",
       "..                     ...  \n",
       "229             Republican  \n",
       "230             Republican  \n",
       "231             Republican  \n",
       "232             Republican  \n",
       "233             Democratic  \n",
       "\n",
       "[234 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches['party'] = df_speeches.president.apply(pres_to_party)\n",
    "df_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party\n",
       "Democratic               90\n",
       "Democratic-Republican    28\n",
       "Federalist                4\n",
       "National Union            4\n",
       "Republican               93\n",
       "Unaffiliated             11\n",
       "Whig                      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches.groupby('party').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider Republican and Democratic here (df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>word</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "      <td>[senate, house, representative, give, pleasure...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "      <td>[deliver, person, joint, session, mr, presiden...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "      <td>[since, close, last, congress, nation, lose, p...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grover Cleveland</td>\n",
       "      <td>To the Congress of the United States:\\r\\n\\r\\n...</td>\n",
       "      <td>1886</td>\n",
       "      <td>[congress, united, state, discharge, constitut...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1905</td>\n",
       "      <td>[senate, house, representative, people, countr...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Thank you very much. Mr. Speaker, Mr. Vice Pre...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[thank, much, mr, speaker, mr, vice, president...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[mr, speaker, mr, vice, president, member, con...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>Madame Speaker.Madame Vice President.No presid...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[madame, speakermadame, vice, presidentno, pre...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                president                                               text  \\\n",
       "0        William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "1    Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "2         Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "3        Grover Cleveland   To the Congress of the United States:\\r\\n\\r\\n...   \n",
       "4      Theodore Roosevelt   To the Senate and House of Representatives:\\r...   \n",
       "..                    ...                                                ...   \n",
       "178       Donald J. Trump  Thank you very much. Mr. Speaker, Mr. Vice Pre...   \n",
       "179       Donald J. Trump  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "180       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "181       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "182       Joseph R. Biden  Madame Speaker.Madame Vice President.No presid...   \n",
       "\n",
       "     year                                               word       party  \n",
       "0    1897  [senate, house, representative, give, pleasure...  Republican  \n",
       "1    1960  [deliver, person, joint, session, mr, presiden...  Republican  \n",
       "2    1923  [since, close, last, congress, nation, lose, p...  Republican  \n",
       "3    1886  [congress, united, state, discharge, constitut...  Democratic  \n",
       "4    1905  [senate, house, representative, people, countr...  Republican  \n",
       "..    ...                                                ...         ...  \n",
       "178  2017  [thank, much, mr, speaker, mr, vice, president...  Republican  \n",
       "179  2018  [mr, speaker, mr, vice, president, member, con...  Republican  \n",
       "180  2019  [madam, speaker, mr, vice, president, member, ...  Republican  \n",
       "181  2020  [madam, speaker, mr, vice, president, member, ...  Republican  \n",
       "182  2021  [madame, speakermadame, vice, presidentno, pre...  Democratic  \n",
       "\n",
       "[183 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_speeches[df_speeches.party.isin(['Republican', 'Democratic'])]\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Naive Bayes Classifier (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Build a Naive Bayes Classifier. Use the first 140 speeches for training and the others for testing. Report the accuracy on test data and the most informative features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               homestead = True           Republ : Democr =     12.3 : 1.0\n",
      "                protocol = True           Republ : Democr =     10.3 : 1.0\n",
      "                   expel = True           Democr : Republ =      9.7 : 1.0\n",
      "                  andrew = True           Democr : Republ =      9.0 : 1.0\n",
      "               telegraph = True           Republ : Democr =      9.0 : 1.0\n",
      "                  whilst = True           Democr : Republ =      8.3 : 1.0\n",
      "               affection = True           Democr : Republ =      7.7 : 1.0\n",
      "               appliance = True           Republ : Democr =      7.7 : 1.0\n",
      "            coordination = True           Republ : Democr =      7.7 : 1.0\n",
      "               publicity = True           Republ : Democr =      7.7 : 1.0\n",
      "Accuracy: 0.7209302325581395\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy as nltk_accuracy\n",
    "#from nltk.metrics import accuracy as nltk_accuracy\n",
    "\n",
    "train_data = df.iloc[:140]\n",
    "test_data = df.iloc[140:]\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "train_features = [(word_feats(text), party) for text, party in zip(train_data['word'], train_data['party'])]\n",
    "test_features = [(word_feats(text), party) for text, party in zip(test_data['word'], test_data['party'])]\n",
    "\n",
    "clf = NaiveBayesClassifier.train(train_features)\n",
    "\n",
    "test_accuracy = nltk_accuracy(clf, test_features)\n",
    "\n",
    "# Get the most informative features\n",
    "most_informative_features = clf.show_most_informative_features(10)\n",
    "\n",
    "print(\"Accuracy: \" + str(test_accuracy))\n",
    "most_informative_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Word2Vec + Classification (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Build up a word2vec model to generate word vectors. Remember to choose the appropriate parameters for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16813112, 18223600)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=df_speeches['word'], vector_size=100, window=5, min_count=3, workers=4, sg=1)\n",
    "model.train(df_speeches['word'],total_examples=len(df_speeches['word']),epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to test your model. Is the output of your model correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code, embedding word vectors into a 2D plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_k_dim(M, k=2):  \n",
    "    \"\"\"\n",
    "    Reduces the dimensionality of a matrix M to k dimensions using Truncated Singular Value Decomposition (SVD).\n",
    "    \n",
    "    Parameters:\n",
    "    - M (array-like): The high-dimensional data matrix to be reduced. Each row represents a data point.\n",
    "    - k (int, optional): The target number of dimensions. Default is 2.\n",
    "    \"\"\"\n",
    "\n",
    "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
    "    M_reduced = None\n",
    "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
    "\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    svd = TruncatedSVD(n_components = k, n_iter = n_iters,random_state = 1)\n",
    "    #a   = svd.fit(M)\n",
    "    M_reduced = svd.fit_transform(M)\n",
    "    print(\"Done.\")\n",
    "    return M_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_of_vectors(wv_from_bin):\n",
    "    \"\"\"\n",
    "    Creates a matrix of word vectors from a word2vec model and a corresponding dictionary to map words to their indices in the matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - wv_from_bin: A word2vec model loaded, for example, using Gensim's KeyedVectors.\n",
    "    \"\"\"\n",
    "\n",
    "    import random\n",
    "    words = list(wv_from_bin.key_to_index.keys())\n",
    "    print(\"Shuffling words ...\")\n",
    "    random.shuffle(words)\n",
    "    print(f\"Putting {len(words)} words into word2Ind and matrix M...\")\n",
    "    word2Ind = {}\n",
    "    M = []\n",
    "    curInd = 0\n",
    "    for w in words:\n",
    "        try:\n",
    "            # Use get_vector method instead of deprecated word_vec\n",
    "            M.append(wv_from_bin.get_vector(w))\n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    M = np.stack(M)\n",
    "    print(\"Done.\")\n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(M_reduced, word2Ind, words):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot of word embeddings for a subset of words.\n",
    "\n",
    "    Parameters:\n",
    "    - M_reduced (numpy.ndarray): A matrix of word embeddings reduced to 2 dimensions. Each row corresponds to a word.\n",
    "    - word2Ind (dict): A dictionary mapping words to their indices in the M_reduced matrix.\n",
    "    - words (list of str): A list of words to plot. These words should be keys in word2Ind.    \n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "    for i,word in enumerate(words):\n",
    "        x = M_reduced[(word2Ind.get(word),0)]\n",
    "        y = M_reduced[(word2Ind.get(word),1)]\n",
    "        plt.scatter(x, y, marker='x', color='red')\n",
    "        plt.text(x+0.01, y+0.01, word, fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling words ...\n",
      "Putting 10885 words into word2Ind and matrix M...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "M, word2Ind = get_matrix_of_vectors(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 10885 words...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# truncated 2D word2vec matrix\n",
    "M_reduced = reduce_to_k_dim(M, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2D visualization\n",
    "words = [\"free\",\"wonderful\",\"quiet\",\"impressive\",\"good\",'government','sad','happy','serious','false','sovereign']\n",
    "plot_embeddings(M_reduced, word2Ind, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Multi-layer Perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Build a Multi-layer Perceptron (MLP) Classifier to predicte the political party of the president using mean word vectors (the average of word vectors for each review) as features. Use the first 140 speeches for training and the others for testing. Report the accuracy on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Create Average Word Vectors for each Review                      ###\n",
    "##############################################################################\n",
    "mean_vectors = [np.mean([model.wv[word] for word in doc if word in model.wv], axis=0) for doc in df['word'] if len(doc) > 0]\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=DeprecationWarning) # ignore warning during model training\n",
    "    \n",
    "    ##############################################################################\n",
    "    ### TODO: Build an MLP Classifier and Report Accuracy on Test Data         ###\n",
    "    ##############################################################################\n",
    "X_train = mean_vectors[:140]\n",
    "X_test = mean_vectors[140:]\n",
    "y_train = df['party'][:140]\n",
    "y_test = df['party'][140:]\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', random_state=1)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "y_pred = mlp_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: BERT and Emotions Classification (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Demszky et al. (2020) introduced the GoEmotions dataset, consisting of 58K Reddit comments, each labeled for one or more of 27 emotions or neutral (28 in total). Specifically, the dataset encompasses comments from Reddit's inception in 2005 up to January 2019. The subreddits with at least 10k comments were selected, and non-English comments are removed. Demszky et al. (2020) preprocess the comments data to reduce profanity and balance between categories. Te be specific, the following preprocessings are performed: Reducing profanity, manual review, sentiment balancing, emotion balancing, subreddit balancing, and masking. After preprocessing, the size of the total GoEmotions dataset is 54,263, including 43,410 for training (80%), 5,426 for validation (10%), and 5,427 for test (10%).\n",
    "\n",
    "There are 28 emotions: neutral, admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise. \n",
    "\n",
    "You can refer to the GoEmotions paper or HuggingFace: https://huggingface.co/datasets/go_emotions.\n",
    "\n",
    "We only have a subsample of this dataset for your final project for simplicity. We have provided with the data file `reddit.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings\n",
    "\n",
    "**BERT** (Bidirectional Encoder Representations from Transformers) is a revolutionary model in the field of natural language processing (NLP) introduced by researchers at Google in 2018. BERT's breakthrough is its ability to train language models based on the entire set of words in a sentence or query (bidirectionally), rather than the traditional way of training on the order of words (left-to-right or right-to-left). This approach allows the model to capture the context of a word based on all of its surroundings, leading to a deeper understanding of language.\n",
    "\n",
    "Here are some key concepts that are good to know:\n",
    "\n",
    "- **Transformer**: BERT is built on the Transformer architecture, introduced in the paper \"Attention is All You Need\" by Vaswani et al. The Transformer model uses self-attention mechanisms to weigh the significance of different words in a sentence. Unlike previous models that processed words in sequence, the Transformer treats sentences as a whole, enabling parallel processing and significantly reducing training times.\n",
    "\n",
    "- **Bidirectional Context**: BERT's key innovation is its bidirectional training of the Transformer. Traditional language models were limited to unidirectional training, which could only consider the context from one direction (either from left to right or vice versa). BERT, however, uses a \"masked language model\" (MLM) pre-training objective, where some percentage of the input tokens are masked at random, and the goal is to predict these masked tokens based on the context provided by the non-masked tokens in the sequence.\n",
    "\n",
    "- **Pre-training** and **Fine-tuning**\n",
    "\n",
    "    - Pre-training: BERT is pre-trained on a large corpus of text from the BookCorpus and English Wikipedia. During pre-training, it learns language representations by optimizing two objectives: the Masked Language Model (MLM) and Next Sentence Prediction (NSP). MLM helps BERT understand the bidirectional context of words, while NSP enables it to understand the relationships between sentences.\n",
    "    \n",
    "    - Fine-tuning: After pre-training, BERT can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering, sentiment analysis, and language inference, without substantial modifications to the model architecture.\n",
    "\n",
    "Here are some technical details about BERT if you are interested:\n",
    "\n",
    "- **Model size**: BERT comes in several sizes, the two primary variants being BERT-Base and BERT-Large. BERT-Base consists of 12 layers (transformer blocks), 768 hidden units (size of the embeddings), and 12 self-attention heads, totaling about 110 million parameters. BERT-Large upscales this to 24 layers, 1024 hidden units, and 16 self-attention heads, totaling about 340 million parameters.\n",
    "\n",
    "- **Input representation**: BERT's input representation is designed to handle a wide variety of NLP tasks without modification. Each input embedding is a combination of three embeddings:\n",
    "\n",
    "    - Token Embeddings: WordPiece embeddings with a 30,000 token vocabulary.\n",
    "    \n",
    "    - Segment Embeddings: Differentiated embeddings to distinguish between sentences in tasks that involve multiple sentences (e.g., question answering).\n",
    "    \n",
    "    - Positional Embeddings: To encode the sequence order of words.\n",
    "\n",
    "- **Attention Mechanism**: The core of BERT's Transformer architecture is the attention mechanism, specifically \"multi-head self-attention\". This mechanism allows the model to focus on different parts of the input sequence when understanding each word, considering the entire context of the sentence or sequence, both to the left and the right of the target word.\n",
    "\n",
    "https://lilianweng.github.io/posts/2019-01-31-lm/ is a great article to read, introducing a list of methods and algorithm in Natural Language Processing and Language Models. You can read it for your own interest and know more about the progress in NLP (until 5 years ago)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "      <td>eecwqtt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "      <td>ed5f85d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "      <td>een27c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "      <td>eelgwd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "      <td>eem5uti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion       id\n",
       "0  I’m really sorry about your situation :( Altho...      25  eecwqtt\n",
       "1    It's wonderful because it's awful. At not with.       0  ed5f85d\n",
       "2  Kings fan here, good luck to you guys! Will be...      13  een27c3\n",
       "3  I didn't know that, thank you for teaching me ...      15  eelgwd1\n",
       "4  They got bored from haunting earth for thousan...      27  eem5uti"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"reddit.tsv\", sep=\"\\t\", header=None)\n",
    "df.columns = ['text', 'emotion', 'id']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Construct a BERT tokenizer and model based on the pre-trained model 'bert-base-uncased' ###\n",
    "### TODO: Encode the text into tokens ###\n",
    "##############################################################################\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BERT embeddings for text data\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=50)\n",
    "    \n",
    "    # Forward pass through BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    # Extract the output embeddings and mean pooling\n",
    "    embedding = outputs.last_hidden_state.mean(axis=(0, 1)).numpy()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying BERT embeddings: 100%|██████████| 5427/5427 [10:56<00:00,  8.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# ~5-10 minutes running time\n",
    "tqdm.pandas(desc=\"Applying BERT embeddings\")\n",
    "\n",
    "# Convert text to BERT embeddings\n",
    "df['embedding'] = df['text'].progress_apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "      <td>eecwqtt</td>\n",
       "      <td>[0.08825616, -0.0671884, 0.15275933, -0.310085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "      <td>ed5f85d</td>\n",
       "      <td>[0.06496291, 0.1867005, 0.26324436, 0.097168, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "      <td>een27c3</td>\n",
       "      <td>[0.30238122, -0.19871931, 0.57909536, 0.101910...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "      <td>eelgwd1</td>\n",
       "      <td>[0.10757128, 0.116430484, 0.12003426, 0.152835...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "      <td>eem5uti</td>\n",
       "      <td>[0.6161463, 0.04139359, 0.23162575, 0.30271912...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion       id  \\\n",
       "0  I’m really sorry about your situation :( Altho...      25  eecwqtt   \n",
       "1    It's wonderful because it's awful. At not with.       0  ed5f85d   \n",
       "2  Kings fan here, good luck to you guys! Will be...      13  een27c3   \n",
       "3  I didn't know that, thank you for teaching me ...      15  eelgwd1   \n",
       "4  They got bored from haunting earth for thousan...      27  eem5uti   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.08825616, -0.0671884, 0.15275933, -0.310085...  \n",
       "1  [0.06496291, 0.1867005, 0.26324436, 0.097168, ...  \n",
       "2  [0.30238122, -0.19871931, 0.57909536, 0.101910...  \n",
       "3  [0.10757128, 0.116430484, 0.12003426, 0.152835...  \n",
       "4  [0.6161463, 0.04139359, 0.23162575, 0.30271912...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data with BERT embeddings to .pkl file so that we can use it later and avoid re-running the time-consuming codes above\n",
    "with open('data_with_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "      <td>eecwqtt</td>\n",
       "      <td>[0.08825616, -0.0671884, 0.15275933, -0.310085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "      <td>ed5f85d</td>\n",
       "      <td>[0.06496291, 0.1867005, 0.26324436, 0.097168, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "      <td>een27c3</td>\n",
       "      <td>[0.30238122, -0.19871931, 0.57909536, 0.101910...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "      <td>eelgwd1</td>\n",
       "      <td>[0.10757128, 0.116430484, 0.12003426, 0.152835...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "      <td>eem5uti</td>\n",
       "      <td>[0.6161463, 0.04139359, 0.23162575, 0.30271912...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion       id  \\\n",
       "0  I’m really sorry about your situation :( Altho...      25  eecwqtt   \n",
       "1    It's wonderful because it's awful. At not with.       0  ed5f85d   \n",
       "2  Kings fan here, good luck to you guys! Will be...      13  een27c3   \n",
       "3  I didn't know that, thank you for teaching me ...      15  eelgwd1   \n",
       "4  They got bored from haunting earth for thousan...      27  eem5uti   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.08825616, -0.0671884, 0.15275933, -0.310085...  \n",
       "1  [0.06496291, 0.1867005, 0.26324436, 0.097168, ...  \n",
       "2  [0.30238122, -0.19871931, 0.57909536, 0.101910...  \n",
       "3  [0.10757128, 0.116430484, 0.12003426, 0.152835...  \n",
       "4  [0.6161463, 0.04139359, 0.23162575, 0.30271912...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data with BERT embeddings\n",
    "with open('data_with_embeddings.pkl', 'rb') as f1:\n",
    "    df1 = pickle.load(f1)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Use the BERT embeddings as features and the emotion as the target variable ###\n",
    "### TODO: Split the data into training and testing sets (test_size=0.2) ###\n",
    "##############################################################################\n",
    "# Create an array of embeddings and the target variable\n",
    "#X = np.array(df1['embedding'].tolist())\n",
    "#y = df1['emotion'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1['embedding'].tolist(),\n",
    "                                                    df1['emotion'].values, test_size=0.2, random_state=42)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39226519337016574\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "### TODO: Perform Logistic Regression to fit the training data, predict the emotion, \n",
    "### and calculate the prediction accuracy ###\n",
    "##############################################################################\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, max_iter=100)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.3370165745856354\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "### TODO: Perform Random Forest to fit the training data, predict the emotion, \n",
    "### and calculate the prediction accuracy ###\n",
    "##############################################################################\n",
    "rf_classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest accuracy: {accuracy_rf}')\n",
    "\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
